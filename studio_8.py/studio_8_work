import requests
import time
from bs4 import BeautifulSoup as bs
from collections import Counter 

class Quote:
    def __init__(self, author, text, tags):
        self.author = author
        self.tags = tags
        self.text = text


def main():
    url = "https://quotes.toscrape.com/"
    r = requests.get(url)
    soup = bs(r.content, "html.parser")
    
    #scrape_quotes(soup)
    quotes = []
    while True:
        time.sleep(1)
        relative_url = get_next_url(soup)
        if relative_url is None:
            break
        next_page = url + relative_url

        r = requests.get(next_page)
        soup = bs(r.content, "html.parser")
        quotes.extend(scrape_quotes(soup))

    list_of_tags = find_dupe_tags(quotes)
    most_common_tags = Counter(list_of_tags).most_common(10)
    print("Answer#1")
    print(most_common_tags)
    print("--------------------------------------------")

    get_shortest_and_Longest(quotes)

    list_of_authors = find_all_authors(quotes)
    most_common_authors = Counter(list_of_authors).most_common(14)
    print("Answer#4")
    print(most_common_authors)

   
   

    return

def find_all_authors(quotes):
    authors_list = []
    for quote in quotes:
        authors_list.append(quote.author)

    return authors_list


def find_dupe_tags(quotes):
    tag_list = []
    for quote in quotes:
        tag_list.append(quote.tags) 
        
    flattened_list = [value for sublist in tag_list for value in sublist]

    
    return flattened_list

            



def get_shortest_and_Longest(quotes):
    longest = 0 
    shortest = 100000
    longest_quote = ""
    shortest_quote = ""

    for quote in quotes:
        
        if len(quote.text) > longest:
            longest = len(quote.text)
            longest_quote = quote.text

        if len(quote.text) < shortest:
            shortest = len(quote.text)
            shortest_quote = quote.text
    print("Answer#2 " + str(shortest))
    print("-------------------------------")
    print("Answer#3 " + str(longest))
    print("-------------------------------")

    return

#long 1084
#short 34


def get_next_url(soup: bs):
    list_item = soup.find("li", {"class": "next"})
    if list_item is None:
        return None
    anchor = list_item.find("a")
    url = anchor["href"]

    return url

def scrape_quotes(soup: bs):
    quotes = soup.find_all("div", {"class": "quote"})
    quotes_list = []
    for quote in quotes:

        text = quote.find("span", {"class": "text"}).get_text(strip=True)
        print(text)
        author = quote.find("small", {"class": "author"}).get_text(strip=True)
        print(author)
        tags = quote.find_all("a", {"class": "tag"})
        tags_text = []

        for tag in tags:
            tags_text.append(tag.get_text(strip=True))

        print(tags_text)
        print("----------------------------------------------------")
       
        quotes_list.append(Quote(author, text, tags_text))
       

    return quotes_list







if __name__ == "__main__":
    main()